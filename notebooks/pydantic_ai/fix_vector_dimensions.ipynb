{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bca3806b",
   "metadata": {},
   "source": [
    "# Fix Vector Dimension Mismatch in RAG Database\n",
    "\n",
    "This notebook demonstrates how to fix the vector dimension mismatch error that occurs when the database expects 1536 dimensions but the embedding model produces 1024 dimensions.\n",
    "\n",
    "## Error Context\n",
    "```\n",
    "asyncpg.exceptions.DataError: expected 1536 dimensions, not 1024\n",
    "```\n",
    "\n",
    "This happens when:\n",
    "- Database was created with OpenAI embedding dimensions (1536)\n",
    "- But now using Ollama embedding model like `mxbai-embed-large` (1024 dimensions)\n",
    "\n",
    "## Solution\n",
    "We'll reset the database schema to match the current embedding model dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10e666de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n",
      "Python version: 3.12.9 (main, Mar 23 2025, 16:07:08) [GCC 14.2.0]\n",
      "Working directory: /home/user/projects/ai_stack/notebooks/pydantic_ai\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "import asyncio\n",
    "import asyncpg\n",
    "import os\n",
    "import sys\n",
    "from pydantic import BaseModel, Field, ValidationError\n",
    "from typing import List\n",
    "import numpy as np\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a62b6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current embedding model: mxbai-embed-large\n",
      "Required vector dimensions: 1024\n",
      "Database: postgresql://postgres:postgres@localhost:54320/pydantic_ai_rag\n"
     ]
    }
   ],
   "source": [
    "# Database Configuration\n",
    "DATABASE_CONFIG = {\n",
    "    \"server_dsn\": \"postgresql://postgres:postgres@localhost:54320\",\n",
    "    \"database\": \"pydantic_ai_rag\"\n",
    "}\n",
    "\n",
    "# Embedding Models and their dimensions\n",
    "EMBEDDING_DIMENSIONS = {\n",
    "    \"all-minilm\": 384,\n",
    "    \"mxbai-embed-large\": 1024, \n",
    "    \"nomic-embed-text\": 768,\n",
    "    \"text-embedding-3-small\": 1536,  # OpenAI model\n",
    "    \"bge-large\": 1024,\n",
    "    \"snowflake-arctic-embed\": 1024\n",
    "}\n",
    "\n",
    "# Current configuration (should match your rag.py file)\n",
    "CURRENT_EMBEDDING_MODEL = \"mxbai-embed-large\"\n",
    "CURRENT_VECTOR_DIMENSIONS = EMBEDDING_DIMENSIONS[CURRENT_EMBEDDING_MODEL]\n",
    "\n",
    "print(f\"Current embedding model: {CURRENT_EMBEDDING_MODEL}\")\n",
    "print(f\"Required vector dimensions: {CURRENT_VECTOR_DIMENSIONS}\")\n",
    "print(f\"Database: {DATABASE_CONFIG['server_dsn']}/{DATABASE_CONFIG['database']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c067bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current embedding dimensions: 1024\n",
      "Database expects: 1536 dimensions\n",
      "Dimension mismatch: True\n",
      "First 5 values of embedding: [-0.11674921305184428, 0.735286238037038, 0.37432037616766584, 1.1288451177377212, -1.1543849541254774]\n"
     ]
    }
   ],
   "source": [
    "# Simulate Data with Incorrect Dimensions\n",
    "# This simulates what happens when we have embedding data from the new model\n",
    "# but the database expects the old dimensions\n",
    "\n",
    "# Simulate embedding from mxbai-embed-large (1024 dimensions)\n",
    "current_embedding = np.random.randn(1024).tolist()\n",
    "\n",
    "# Simulate what the database currently expects (1536 dimensions from OpenAI)\n",
    "expected_old_dimensions = 1536\n",
    "\n",
    "print(f\"Current embedding dimensions: {len(current_embedding)}\")\n",
    "print(f\"Database expects: {expected_old_dimensions} dimensions\")\n",
    "print(f\"Dimension mismatch: {len(current_embedding) != expected_old_dimensions}\")\n",
    "print(f\"First 5 values of embedding: {current_embedding[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2579dc9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Pydantic models defined\n",
      "   Expected vector dimensions: 1024\n",
      "   Embedding model: mxbai-embed-large\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/projects/ai_stack/notebooks/pydantic_ai/.venv/lib/python3.12/site-packages/pydantic/_internal/_config.py:373: UserWarning: Valid config keys have changed in V2:\n",
      "* 'schema_extra' has been renamed to 'json_schema_extra'\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Define Pydantic Model for Validation\n",
    "class EmbeddingVector(BaseModel):\n",
    "    \"\"\"Pydantic model to validate embedding dimensions\"\"\"\n",
    "    vector: List[float] = Field(..., min_items=CURRENT_VECTOR_DIMENSIONS, max_items=CURRENT_VECTOR_DIMENSIONS)\n",
    "    \n",
    "    class Config:\n",
    "        schema_extra = {\n",
    "            \"example\": {\n",
    "                \"vector\": [0.1] * CURRENT_VECTOR_DIMENSIONS\n",
    "            }\n",
    "        }\n",
    "\n",
    "class DocumentSection(BaseModel):\n",
    "    \"\"\"Pydantic model for document sections with embeddings\"\"\"\n",
    "    url: str\n",
    "    title: str\n",
    "    content: str\n",
    "    embedding: List[float] = Field(..., min_items=CURRENT_VECTOR_DIMENSIONS, max_items=CURRENT_VECTOR_DIMENSIONS)\n",
    "\n",
    "print(f\"‚úÖ Pydantic models defined\")\n",
    "print(f\"   Expected vector dimensions: {CURRENT_VECTOR_DIMENSIONS}\")\n",
    "print(f\"   Embedding model: {CURRENT_EMBEDDING_MODEL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a6490f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Pydantic validation...\n",
      "‚úÖ Validation successful for 1024 dimensions\n",
      "‚ùå Expected validation failure for wrong dimensions: 1536\n",
      "   Error: 1 validation error for EmbeddingVector\n",
      "vector\n",
      "  List should have at most 1024 items after validation, not 1536 [type=too_long, input_value=[0.2739007144989292, 1.08...43, -0.6672567075569252], input_type=list]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/too_long\n",
      "‚úÖ Document section validation successful\n"
     ]
    }
   ],
   "source": [
    "# Validate Data Dimensions with Pydantic\n",
    "print(\"Testing Pydantic validation...\")\n",
    "\n",
    "# Test with correct dimensions\n",
    "try:\n",
    "    correct_embedding = np.random.randn(CURRENT_VECTOR_DIMENSIONS).tolist()\n",
    "    valid_vector = EmbeddingVector(vector=correct_embedding)\n",
    "    print(f\"‚úÖ Validation successful for {len(correct_embedding)} dimensions\")\n",
    "except ValidationError as e:\n",
    "    print(f\"‚ùå Validation failed: {e}\")\n",
    "\n",
    "# Test with incorrect dimensions (simulating the error)\n",
    "try:\n",
    "    wrong_embedding = np.random.randn(1536).tolist()  # Old OpenAI dimensions\n",
    "    invalid_vector = EmbeddingVector(vector=wrong_embedding)\n",
    "    print(f\"‚úÖ Validation successful for {len(wrong_embedding)} dimensions\")\n",
    "except ValidationError as e:\n",
    "    print(f\"‚ùå Expected validation failure for wrong dimensions: {len(wrong_embedding)}\")\n",
    "    print(f\"   Error: {e}\")\n",
    "\n",
    "# Test document section validation\n",
    "try:\n",
    "    doc_section = DocumentSection(\n",
    "        url=\"https://example.com/doc\",\n",
    "        title=\"Test Document\",\n",
    "        content=\"This is test content\",\n",
    "        embedding=current_embedding\n",
    "    )\n",
    "    print(f\"‚úÖ Document section validation successful\")\n",
    "except ValidationError as e:\n",
    "    print(f\"‚ùå Document section validation failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b60abec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demonstrating asyncpg DataError...\n",
      "‚úÖ Insert successful\n",
      "‚úÖ Insert successful\n"
     ]
    }
   ],
   "source": [
    "# Handle asyncpg DataError Exception\n",
    "async def demonstrate_data_error():\n",
    "    \"\"\"Demonstrate how the DataError occurs and how to handle it\"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Connect to the database\n",
    "        server_dsn = DATABASE_CONFIG[\"server_dsn\"]\n",
    "        database = DATABASE_CONFIG[\"database\"]\n",
    "        \n",
    "        conn = await asyncpg.connect(f\"{server_dsn}/{database}\")\n",
    "        \n",
    "        # Try to insert data with wrong dimensions (this will fail if table exists with old schema)\n",
    "        wrong_embedding = np.random.randn(1536).tolist()  # Old dimensions\n",
    "        \n",
    "        try:\n",
    "            await conn.execute(\n",
    "                \"INSERT INTO doc_sections (url, title, content, embedding) VALUES ($1, $2, $3, $4)\",\n",
    "                \"https://test.com\",\n",
    "                \"Test\",\n",
    "                \"Test content\",\n",
    "                str(wrong_embedding)  # This might cause the error\n",
    "            )\n",
    "            print(\"‚úÖ Insert successful\")\n",
    "        except asyncpg.exceptions.DataError as e:\n",
    "            print(f\"‚ùå DataError caught: {e}\")\n",
    "            print(\"   This is the exact error you encountered!\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è  Other database error: {e}\")\n",
    "        \n",
    "        await conn.close()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Connection error: {e}\")\n",
    "        print(\"   Make sure PostgreSQL is running and accessible\")\n",
    "\n",
    "# Run the demonstration\n",
    "print(\"Demonstrating asyncpg DataError...\")\n",
    "await demonstrate_data_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae736e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting database schema fix...\n",
      "üîß Fixing database schema...\n",
      "   ‚úÖ Dropped existing doc_sections table\n",
      "   ‚úÖ Created new table with 1024 dimensions\n",
      "   ‚úÖ Successfully inserted test data with correct dimensions\n",
      "   ‚úÖ Verified: Retrieved document with ID 1\n",
      "\n",
      "üéâ Database schema fixed successfully!\n",
      "   Table now accepts 1024-dimensional vectors\n",
      "   Compatible with embedding model: mxbai-embed-large\n"
     ]
    }
   ],
   "source": [
    "# Fix Data Dimensions and Retry Execution\n",
    "async def fix_database_schema():\n",
    "    \"\"\"Drop and recreate the table with correct dimensions\"\"\"\n",
    "    \n",
    "    try:\n",
    "        server_dsn = DATABASE_CONFIG[\"server_dsn\"]\n",
    "        database = DATABASE_CONFIG[\"database\"]\n",
    "        \n",
    "        # Connect to database\n",
    "        conn = await asyncpg.connect(f\"{server_dsn}/{database}\")\n",
    "        \n",
    "        print(\"üîß Fixing database schema...\")\n",
    "        \n",
    "        # Drop existing table (this removes the dimension constraint)\n",
    "        await conn.execute(\"DROP TABLE IF EXISTS doc_sections CASCADE\")\n",
    "        print(\"   ‚úÖ Dropped existing doc_sections table\")\n",
    "        \n",
    "        # Create new table with correct dimensions\n",
    "        new_schema = f\"\"\"\n",
    "        CREATE EXTENSION IF NOT EXISTS vector;\n",
    "        \n",
    "        CREATE TABLE doc_sections (\n",
    "            id serial PRIMARY KEY,\n",
    "            url text NOT NULL UNIQUE,\n",
    "            title text NOT NULL,\n",
    "            content text NOT NULL,\n",
    "            embedding vector({CURRENT_VECTOR_DIMENSIONS}) NOT NULL\n",
    "        );\n",
    "        \n",
    "        CREATE INDEX idx_doc_sections_embedding ON doc_sections \n",
    "        USING hnsw (embedding vector_l2_ops);\n",
    "        \"\"\"\n",
    "        \n",
    "        await conn.execute(new_schema)\n",
    "        print(f\"   ‚úÖ Created new table with {CURRENT_VECTOR_DIMENSIONS} dimensions\")\n",
    "        \n",
    "        # Test insertion with correct dimensions\n",
    "        correct_embedding = np.random.randn(CURRENT_VECTOR_DIMENSIONS).tolist()\n",
    "        \n",
    "        # Validate with Pydantic first\n",
    "        doc_section = DocumentSection(\n",
    "            url=\"https://test.com/fixed\",\n",
    "            title=\"Test Document (Fixed)\",\n",
    "            content=\"This is test content with correct dimensions\",\n",
    "            embedding=correct_embedding\n",
    "        )\n",
    "        \n",
    "        # Insert the validated data\n",
    "        await conn.execute(\n",
    "            \"INSERT INTO doc_sections (url, title, content, embedding) VALUES ($1, $2, $3, $4)\",\n",
    "            doc_section.url,\n",
    "            doc_section.title,\n",
    "            doc_section.content,\n",
    "            str(doc_section.embedding)\n",
    "        )\n",
    "        \n",
    "        print(\"   ‚úÖ Successfully inserted test data with correct dimensions\")\n",
    "        \n",
    "        # Verify the data\n",
    "        result = await conn.fetchrow(\"SELECT * FROM doc_sections WHERE url = $1\", doc_section.url)\n",
    "        print(f\"   ‚úÖ Verified: Retrieved document with ID {result['id']}\")\n",
    "        \n",
    "        await conn.close()\n",
    "        print(\"\\nüéâ Database schema fixed successfully!\")\n",
    "        print(f\"   Table now accepts {CURRENT_VECTOR_DIMENSIONS}-dimensional vectors\")\n",
    "        print(f\"   Compatible with embedding model: {CURRENT_EMBEDDING_MODEL}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error fixing database: {e}\")\n",
    "\n",
    "# Execute the fix\n",
    "print(\"Starting database schema fix...\")\n",
    "await fix_database_schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41b80e5",
   "metadata": {},
   "source": [
    "## Next Steps: Rebuild Your RAG Database\n",
    "\n",
    "After running this notebook, your database schema is now fixed. However, you need to rebuild the search database with the correct embeddings.\n",
    "\n",
    "### Option 1: Run the build command directly\n",
    "```bash\n",
    "cd /home/user/projects/ai_stack/notebooks/pydantic_ai\n",
    "python rag.py build\n",
    "```\n",
    "\n",
    "### Option 2: Use your existing script\n",
    "If you have a script that calls the build function, run it now.\n",
    "\n",
    "### Option 3: Test the search functionality\n",
    "```bash\n",
    "cd /home/user/projects/ai_stack/notebooks/pydantic_ai\n",
    "python rag.py search \"How do I configure logfire?\"\n",
    "```\n",
    "\n",
    "### Verification\n",
    "The database now has:\n",
    "- ‚úÖ Correct vector dimensions (1024) for `mxbai-embed-large`\n",
    "- ‚úÖ Updated schema that matches your embedding model\n",
    "- ‚úÖ Proper vector index for efficient similarity search\n",
    "\n",
    "### Important Notes\n",
    "- Any existing embeddings in the old table have been deleted\n",
    "- You need to rebuild the search database from scratch\n",
    "- Future embeddings will work correctly with the new schema"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pydantic_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
