{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a23583b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Imports completed successfully!\n",
      "üåê Ollama endpoint: http://localhost:11434\n",
      "ü§ñ Model: qwen3:8b\n",
      "üí° Using OpenAI-compatible interface with Ollama\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Optional, Any\n",
    "from pydantic import BaseModel, Field\n",
    "from pydantic_ai import Agent\n",
    "from pydantic_ai.models.openai import OpenAIModel\n",
    "from pydantic_ai.providers.openai import OpenAIProvider\n",
    "\n",
    "# Configuration for Ollama using OpenAI-compatible endpoint\n",
    "OLLAMA_BASE_URL = \"http://localhost:11434\"\n",
    "MODEL_NAME = \"qwen3:8b\"  # Updated to use available model\n",
    "\n",
    "# Ollama provides OpenAI-compatible API at /v1/ endpoint\n",
    "ollama_model = OpenAIModel(\n",
    "    model_name=MODEL_NAME, provider=OpenAIProvider(base_url=f\"{OLLAMA_BASE_URL}/v1\")\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Imports completed successfully!\")\n",
    "print(f\"üåê Ollama endpoint: {OLLAMA_BASE_URL}\")\n",
    "print(f\"ü§ñ Model: {MODEL_NAME}\")\n",
    "print(\"üí° Using OpenAI-compatible interface with Ollama\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c19ea82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "city='London' country='United Kingdom'\n",
      "Usage(requests=1, request_tokens=163, response_tokens=157, total_tokens=320)\n"
     ]
    }
   ],
   "source": [
    "class CityLocation(BaseModel):\n",
    "    city: str\n",
    "    country: str\n",
    "\n",
    "\n",
    "ollama_model = OpenAIModel(\n",
    "    model_name=MODEL_NAME, provider=OpenAIProvider(base_url=f\"{OLLAMA_BASE_URL}/v1\")\n",
    ")\n",
    "agent = Agent(ollama_model, output_type=CityLocation)\n",
    "\n",
    "result = await agent.run('Where were the olympics held in 2012?')\n",
    "print(result.output)\n",
    "#> city='London' country='United Kingdom'\n",
    "print(result.usage())\n",
    "#> Usage(requests=1, request_tokens=57, response_tokens=8, total_tokens=65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bff9a7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available models in Ollama:\n",
      "  - qwen3:8b\n",
      "  - gemma3:4b-it-qat\n",
      "  - deepseek-r1:8b\n",
      "  - hf.co/unsloth/DeepSeek-R1-0528-Qwen3-8B-GGUF:Q4_K_XL\n",
      "  - deepseek-r1-qwen3-8b:latest\n",
      "  - llama3.2:1b\n"
     ]
    }
   ],
   "source": [
    "# Let's first check what models are available in Ollama\n",
    "import requests\n",
    "import json\n",
    "\n",
    "try:\n",
    "    response = requests.get(f\"{OLLAMA_BASE_URL}/api/tags\")\n",
    "    if response.status_code == 200:\n",
    "        models = response.json()\n",
    "        print(\"Available models in Ollama:\")\n",
    "        for model in models.get('models', []):\n",
    "            print(f\"  - {model['name']}\")\n",
    "    else:\n",
    "        print(f\"Failed to get models: {response.status_code}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error connecting to Ollama: {e}\")\n",
    "    print(\"Make sure Ollama is running on localhost:11434\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53f24905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Switching to model: qwen3:8b\n",
      "üìù This model should support function calling/tools\n"
     ]
    }
   ],
   "source": [
    "# Let's switch to a model that supports function calling\n",
    "# llama3.2:1b should support tools better than deepseek-r1\n",
    "# MODEL_NAME = \"llama3.2:1b\"\n",
    "MODEL_NAME = \"qwen3:8b\"\n",
    "print(f\"üîÑ Switching to model: {MODEL_NAME}\")\n",
    "print(\"üìù This model should support function calling/tools\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87a9085f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, so the user asked for the top five highest-grossing animated films of 2025. Let me check the search results to see what's available.\n",
      "\n",
      "Looking at the first result from whatsafterthemovie.com, it lists Ne Zha as number 1 with a domestic gross of $20,858,156. But wait, that's just domestic, and the worldwide might be higher. The second result from Wikipedia mentions a list of the 10 highest-grossing animated films of 2025, but the exact top five aren't detailed there. \n",
      "\n",
      "The third result from simplebeen.com talks about Disney's dominance and lists the top 10, but again, the specific top five aren't clear. The fourth result from listchallenges.com mentions Ne Zha 2 as number 1 and lists the top 50, but the top five aren't fully provided. \n",
      "\n",
      "The fifth result is an IMDb list, but it's incomplete, only showing some entries. The sixth result from justjared.com states that Ne Zha 2 is the highest-grossing with $1.72 billion. The seventh result from animesoulking.com also mentions Ne Zha 2 as the highest-grossing. \n",
      "\n",
      "The eighth and ninth results from dexerto.com and digitalspy.com mention Lilo & Stitch and Boonie Bears: Future Reborn as top earners. The last Statista link is about the highest-grossing animated movies ever, including 2025 data. \n",
      "\n",
      "Putting this together, Ne Zha 2 seems to be the top. Then Lilo & Stitch and Boonie Bears are mentioned. But the exact top five isn't fully listed in the results. However, some sources suggest Ne Zha 2, Lilo & Stitch, Boonie Bears: Future Reborn, and others like The Super Mario Bros. Movie and Spider-Man: Across the Spider-Verse. But since the data is from 2025, maybe the actual numbers are different. \n",
      "\n",
      "I need to compile the most consistent answers from the sources. Ne Zha 2 is consistently mentioned as the top. Then Lilo & Stitch and Boonie Bears are next. The other films might be from the 2024 list. Since the user asked for 2025, I should mention that the data is as of 2025 and list the top five based on available info, noting that it's up to the end of 2025.\n",
      "</think>\n",
      "\n",
      "Based on the latest data as of 2025, here are the **top five highest-grossing animated films**:\n",
      "\n",
      "1. **Ne Zha 2** (CMC Pictures)  \n",
      "   - **Worldwide Gross**: ~$1.72 billion (as of February 2025)  \n",
      "   - A Chinese epic redefining animated storytelling with mythological depth.\n",
      "\n",
      "2. **Lilo & Stitch** (Disney)  \n",
      "   - A global phenomenon with strong box office performance, dominating 2025.\n",
      "\n",
      "3. **Boonie Bears: Future Reborn** (China Film Group)  \n",
      "   - A family-friendly adventure film with significant international appeal.\n",
      "\n",
      "4. **The Super Mario Bros. Movie** (Nintendo & Universal)  \n",
      "   - Leveraging iconic IP to secure a top spot in 2025.\n",
      "\n",
      "5. **Spider-Man: Across the Spider-Verse** (Marvel/ Sony)  \n",
      "   - Continued success from the groundbreaking Spider-Verse series.\n",
      "\n",
      "*Note: Data is current as of late 2025, with Ne Zha 2 leading globally. Box office figures may vary slightly depending on regional releases and currency conversions.*\n",
      "Usage(requests=2, request_tokens=2061, response_tokens=1215, total_tokens=3276)\n"
     ]
    }
   ],
   "source": [
    "from pydantic_ai.common_tools.duckduckgo import duckduckgo_search_tool\n",
    "\n",
    "# Create agent with the new model\n",
    "ollama_model = OpenAIModel(\n",
    "    model_name=MODEL_NAME, \n",
    "    provider=OpenAIProvider(base_url=f\"{OLLAMA_BASE_URL}/v1\")\n",
    ")\n",
    "agent = Agent(\n",
    "    ollama_model,\n",
    "    tools=[duckduckgo_search_tool()],\n",
    "    system_prompt='Search DuckDuckGo for the given query and return the results.',\n",
    ")\n",
    "\n",
    "result = await agent.run(\n",
    "    'Can you list the top five highest-grossing animated films of 2025?'\n",
    ")\n",
    "print(result.output)\n",
    "print(result.usage())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "040375eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Agent with tools created successfully!\n",
      "üîß Available tools:\n",
      "  - get_weather(location)\n",
      "  - calculate_circle_area(radius)\n",
      "  - get_current_time()\n",
      "\n",
      "üéØ The agent can now use these tools to answer questions!\n"
     ]
    }
   ],
   "source": [
    "# Example 1: Adding tool functions to a PydanticAI Agent\n",
    "from datetime import datetime\n",
    "import math\n",
    "from pydantic_ai import RunContext\n",
    "\n",
    "# Define response models\n",
    "class WeatherInfo(BaseModel):\n",
    "    location: str\n",
    "    temperature: float\n",
    "    description: str\n",
    "    timestamp: str\n",
    "\n",
    "class MathResult(BaseModel):\n",
    "    operation: str\n",
    "    result: float\n",
    "    explanation: str\n",
    "\n",
    "# Create agent with the new model\n",
    "ollama_model = OpenAIModel(\n",
    "    model_name=MODEL_NAME, \n",
    "    provider=OpenAIProvider(base_url=f\"{OLLAMA_BASE_URL}/v1\")\n",
    ")\n",
    "\n",
    "# Create agent - we'll add tools to this agent\n",
    "agent = Agent(ollama_model)\n",
    "\n",
    "# Method 1: Adding tools using @agent.tool decorator\n",
    "@agent.tool\n",
    "def get_weather(ctx: RunContext, location: str) -> str:\n",
    "    \"\"\"Get current weather for a location.\"\"\"\n",
    "    # This is a mock function - in real use, you'd call a weather API\n",
    "    mock_weather = {\n",
    "        \"London\": {\"temp\": 15, \"desc\": \"Cloudy\"},\n",
    "        \"Paris\": {\"temp\": 18, \"desc\": \"Sunny\"},\n",
    "        \"New York\": {\"temp\": 12, \"desc\": \"Rainy\"},\n",
    "        \"Tokyo\": {\"temp\": 22, \"desc\": \"Clear\"}\n",
    "    }\n",
    "    \n",
    "    weather = mock_weather.get(location, {\"temp\": 20, \"desc\": \"Unknown\"})\n",
    "    return f\"The weather in {location} is {weather['temp']}¬∞C and {weather['desc']}\"\n",
    "\n",
    "@agent.tool\n",
    "def calculate_circle_area(ctx: RunContext, radius: float) -> str:\n",
    "    \"\"\"Calculate the area of a circle given its radius.\"\"\"\n",
    "    if radius <= 0:\n",
    "        return \"Radius must be positive\"\n",
    "    \n",
    "    area = math.pi * radius ** 2\n",
    "    return f\"The area of a circle with radius {radius} is {area:.2f} square units\"\n",
    "\n",
    "@agent.tool\n",
    "def get_current_time(ctx: RunContext) -> str:\n",
    "    \"\"\"Get the current date and time.\"\"\"\n",
    "    now = datetime.now()\n",
    "    return f\"Current time: {now.strftime('%Y-%m-%d %H:%M:%S')}\"\n",
    "\n",
    "print(\"‚úÖ Agent with tools created successfully!\")\n",
    "print(\"üîß Available tools:\")\n",
    "print(\"  - get_weather(location)\")\n",
    "print(\"  - calculate_circle_area(radius)\")\n",
    "print(\"  - get_current_time()\")\n",
    "print(\"\\nüéØ The agent can now use these tools to answer questions!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01e003c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing the agent with different queries that should trigger tools:\n",
      "\n",
      "1Ô∏è‚É£ Testing weather tool:\n",
      "Response: <think>\n",
      "Okay, let me process the user's query and the tool response. The user asked, \"What's the weather like in London?\" I called the get_weather function with London as the location. The response came back as 15¬∞C and Cloudy. Now I need to present this information clearly.\n",
      "\n",
      "First, I'll confirm the location to make sure there's no confusion. Then, state the temperature and the weather condition. I should keep it straightforward and friendly. Maybe add a sentence about the weather being mild or comfortable based on the temperature. Let me check if there's any additional info needed, but since the user only asked for the current weather, sticking to the provided details is best. Alright, time to put it all together in a natural sentence.\n",
      "</think>\n",
      "\n",
      "The current weather in London is 15¬∞C with cloudy conditions. It looks like a mild and comfortable day!\n",
      "Usage: Usage(requests=2, request_tokens=608, response_tokens=311, total_tokens=919)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1269940/3906904202.py:7: DeprecationWarning: `result.data` is deprecated, use `result.output` instead.\n",
      "  print(f\"Response: {result1.data}\")\n"
     ]
    }
   ],
   "source": [
    "# Test the agent with tools\n",
    "print(\"üß™ Testing the agent with different queries that should trigger tools:\\n\")\n",
    "\n",
    "# Test 1: Weather query\n",
    "print(\"1Ô∏è‚É£ Testing weather tool:\")\n",
    "result1 = await agent.run(\"What's the weather like in London?\")\n",
    "print(f\"Response: {result1.data}\")\n",
    "print(f\"Usage: {result1.usage()}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6210d513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2Ô∏è‚É£ Testing math tool:\n",
      "Response: <think>\n",
      "Okay, let me check the user's question again. They asked for the area of a circle with radius 5. The tool response says the area is 78.54 square units. Wait, the function calculate_circle_area was called with radius 5, and the result is 78.54. That makes sense because œÄ times 5 squared is approximately 3.1416 * 25 = 78.54. So the answer is correct. I should present this in a clear way to the user, maybe mention the formula used and the calculation steps. Let me make sure to format the response properly and confirm the answer.\n",
      "</think>\n",
      "\n",
      "The area of a circle with a radius of **5.0** is **78.54 square units**.\n",
      "\n",
      "This is calculated using the formula:  \n",
      "$$\n",
      "\\text{Area} = \\pi \\times r^2 = \\pi \\times 5^2 \\approx 3.1416 \\times 25 \\approx 78.54\n",
      "$$\n",
      "\n",
      "Let me know if you need further clarification! üåü\n",
      "\n",
      "3Ô∏è‚É£ Testing time tool:\n",
      "Response: <think>\n",
      "</think>\n",
      "\n",
      "The current time is 2025-06-17 at 14:32:22.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test 2: Math calculation\n",
    "print(\"2Ô∏è‚É£ Testing math tool:\")\n",
    "result2 = await agent.run(\"What's the area of a circle with radius 5?\")\n",
    "print(f\"Response: {result2.output}\")\n",
    "print()\n",
    "\n",
    "# Test 3: Current time\n",
    "print(\"3Ô∏è‚É£ Testing time tool:\")\n",
    "result3 = await agent.run(\"What time is it now?\")\n",
    "print(f\"Response: {result3.output}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f3ef9a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üìö TOOL FUNCTIONS GUIDE FOR PYDANTIC AI\n",
      "============================================================\n",
      "\n",
      "‚úÖ Method 1: @agent.tool decorator\n",
      "   ‚úì Directly decorate functions\n",
      "   ‚úì Functions must take RunContext as first parameter\n",
      "   ‚úì Best for simple tools\n",
      "\n",
      "‚úÖ Method 2: Standalone Tool objects\n",
      "   ‚úì Create Tool objects explicitly\n",
      "   ‚úì More control over tool configuration\n",
      "   ‚úì Can be reused across multiple agents\n",
      "\n",
      "‚úÖ Method 3: Tools with complex return types\n",
      "   ‚úì Return dictionaries, lists, or custom objects\n",
      "   ‚úì Agent will serialize appropriately\n",
      "\n",
      "‚úÖ Method 4: Tools with error handling\n",
      "   ‚úì Handle errors gracefully\n",
      "   ‚úì Return meaningful error messages\n",
      "   ‚úì Prevent agent crashes\n",
      "\n",
      "üéâ All tool methods demonstrated!\n",
      "üí° Key Points:\n",
      "   ‚Ä¢ Always include RunContext as first parameter\n",
      "   ‚Ä¢ Use descriptive docstrings - the agent uses them\n",
      "   ‚Ä¢ Handle errors gracefully in your tools\n",
      "   ‚Ä¢ Tools can return strings, dicts, or complex objects\n",
      "   ‚Ä¢ Test your tools individually before using with agent\n"
     ]
    }
   ],
   "source": [
    "# üéØ COMPREHENSIVE GUIDE: Different ways to add tool functions in PydanticAI\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"üìö TOOL FUNCTIONS GUIDE FOR PYDANTIC AI\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Method 1: Using @agent.tool decorator (already shown above)\n",
    "print(\"\\n‚úÖ Method 1: @agent.tool decorator\")\n",
    "print(\"   ‚úì Directly decorate functions\")\n",
    "print(\"   ‚úì Functions must take RunContext as first parameter\")\n",
    "print(\"   ‚úì Best for simple tools\")\n",
    "\n",
    "# Method 2: Creating standalone tools and adding them to agent\n",
    "from pydantic_ai.tools import Tool\n",
    "\n",
    "def database_query(ctx: RunContext, table: str, condition: str) -> str:\n",
    "    \"\"\"Mock database query function.\"\"\"\n",
    "    # This would normally connect to a real database\n",
    "    mock_results = {\n",
    "        \"users\": [\"Alice\", \"Bob\", \"Charlie\"],\n",
    "        \"products\": [\"Laptop\", \"Phone\", \"Tablet\"],\n",
    "        \"orders\": [\"Order #1\", \"Order #2\", \"Order #3\"]\n",
    "    }\n",
    "    results = mock_results.get(table, [\"No data found\"])\n",
    "    return f\"Query results from {table} where {condition}: {', '.join(results)}\"\n",
    "\n",
    "# Create a standalone tool\n",
    "db_tool = Tool(database_query)\n",
    "\n",
    "# Create new agent and add the tool\n",
    "agent2 = Agent(ollama_model)\n",
    "agent2._register_tool(db_tool)\n",
    "\n",
    "print(\"\\n‚úÖ Method 2: Standalone Tool objects\")\n",
    "print(\"   ‚úì Create Tool objects explicitly\")\n",
    "print(\"   ‚úì More control over tool configuration\")\n",
    "print(\"   ‚úì Can be reused across multiple agents\")\n",
    "\n",
    "# Method 3: Tools with complex return types\n",
    "@agent2.tool\n",
    "def search_files(ctx: RunContext, pattern: str, file_type: str = \"txt\") -> dict:\n",
    "    \"\"\"Search for files matching a pattern.\"\"\"\n",
    "    mock_files = {\n",
    "        \"txt\": [\"document1.txt\", \"notes.txt\", \"readme.txt\"],\n",
    "        \"py\": [\"main.py\", \"utils.py\", \"test.py\"],\n",
    "        \"md\": [\"README.md\", \"CHANGELOG.md\"]\n",
    "    }\n",
    "    \n",
    "    files = mock_files.get(file_type, [])\n",
    "    matching = [f for f in files if pattern.lower() in f.lower()]\n",
    "    \n",
    "    return {\n",
    "        \"pattern\": pattern,\n",
    "        \"file_type\": file_type,\n",
    "        \"matches\": matching,\n",
    "        \"total_found\": len(matching)\n",
    "    }\n",
    "\n",
    "print(\"\\n‚úÖ Method 3: Tools with complex return types\")\n",
    "print(\"   ‚úì Return dictionaries, lists, or custom objects\")\n",
    "print(\"   ‚úì Agent will serialize appropriately\")\n",
    "\n",
    "# Method 4: Tools with error handling\n",
    "@agent2.tool\n",
    "def safe_division(ctx: RunContext, dividend: float, divisor: float) -> str:\n",
    "    \"\"\"Safely divide two numbers with error handling.\"\"\"\n",
    "    try:\n",
    "        if divisor == 0:\n",
    "            return \"Error: Cannot divide by zero\"\n",
    "        result = dividend / divisor\n",
    "        return f\"{dividend} √∑ {divisor} = {result:.4f}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error in calculation: {str(e)}\"\n",
    "\n",
    "print(\"\\n‚úÖ Method 4: Tools with error handling\")\n",
    "print(\"   ‚úì Handle errors gracefully\")\n",
    "print(\"   ‚úì Return meaningful error messages\")\n",
    "print(\"   ‚úì Prevent agent crashes\")\n",
    "\n",
    "print(\"\\nüéâ All tool methods demonstrated!\")\n",
    "print(\"üí° Key Points:\")\n",
    "print(\"   ‚Ä¢ Always include RunContext as first parameter\")\n",
    "print(\"   ‚Ä¢ Use descriptive docstrings - the agent uses them\")\n",
    "print(\"   ‚Ä¢ Handle errors gracefully in your tools\")\n",
    "print(\"   ‚Ä¢ Tools can return strings, dicts, or complex objects\")\n",
    "print(\"   ‚Ä¢ Test your tools individually before using with agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b9ee8b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing additional tools:\n",
      "\n",
      "üìä Testing database query tool:\n",
      "Response: <think>\n",
      "Okay, let me see. The user asked to search for users in the database where active is true. I called the database_query function with table 'users' and condition 'active = true'. The response came back with the results: Alice, Bob, Charlie. Now I need to present these results to the user in a clear way.\n",
      "\n",
      "First, I should confirm that the query was executed successfully. Then list out the active users. Maybe use a friendly message to inform them of the results. Let me check if there are any other steps needed, but since the user just wanted the search, providing the list should be sufficient. I'll format the response to be easy to read.\n",
      "</think>\n",
      "\n",
      "Here are the active users found in the database:\n",
      "\n",
      "- Alice\n",
      "- Bob\n",
      "- Charlie\n",
      "\n",
      "Let me know if you need any additional information!\n",
      "\n",
      "üîç Testing file search tool:\n",
      "Response: <think>\n",
      "Okay, the user asked to find all Python files containing 'main'. I used the search_files function with pattern 'main' and file_type 'py'. The response shows one match: 'main.py'. So, I should inform the user that there's one file found, which is 'main.py'. I'll present it clearly and ask if they need more details.\n",
      "</think>\n",
      "\n",
      "One Python file was found containing 'main':\n",
      "\n",
      "- `main.py`\n",
      "\n",
      "Let me know if you'd like to see the contents of this file or need further assistance!\n",
      "\n",
      "‚ûó Testing safe division tool:\n",
      "Response: <think>\n",
      "</think>\n",
      "\n",
      "The result of dividing 100 by 7 is approximately 14.2857.\n",
      "\n",
      "‚ú® All tools working correctly!\n"
     ]
    }
   ],
   "source": [
    "# Test the new tools\n",
    "print(\"üß™ Testing additional tools:\")\n",
    "\n",
    "# Test database tool\n",
    "print(\"\\nüìä Testing database query tool:\")\n",
    "result_db = await agent2.run(\"Search for users in the database where active = true\")\n",
    "print(f\"Response: {result_db.output}\")\n",
    "\n",
    "# Test file search tool\n",
    "print(\"\\nüîç Testing file search tool:\")\n",
    "result_files = await agent2.run(\"Find all Python files containing 'main'\")\n",
    "print(f\"Response: {result_files.output}\")\n",
    "\n",
    "# Test division tool\n",
    "print(\"\\n‚ûó Testing safe division tool:\")\n",
    "result_div = await agent2.run(\"What is 100 divided by 7?\")\n",
    "print(f\"Response: {result_div.output}\")\n",
    "\n",
    "print(\"\\n‚ú® All tools working correctly!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pydantic_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
