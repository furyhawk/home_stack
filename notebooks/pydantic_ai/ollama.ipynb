{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a23583b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Imports completed successfully!\n",
      "ğŸŒ Ollama endpoint: http://localhost:11434\n",
      "ğŸ¤– Model: qwen3:8b\n",
      "ğŸ’¡ Using OpenAI-compatible interface with Ollama\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Optional, Any\n",
    "from pydantic import BaseModel, Field\n",
    "from pydantic_ai import Agent\n",
    "from pydantic_ai.models.openai import OpenAIModel\n",
    "from pydantic_ai.providers.openai import OpenAIProvider\n",
    "\n",
    "# Configuration for Ollama using OpenAI-compatible endpoint\n",
    "OLLAMA_BASE_URL = \"http://localhost:11434\"\n",
    "MODEL_NAME = \"qwen3:8b\"  # Updated to use available model\n",
    "\n",
    "# Ollama provides OpenAI-compatible API at /v1/ endpoint\n",
    "ollama_model = OpenAIModel(\n",
    "    model_name=MODEL_NAME, provider=OpenAIProvider(base_url=f\"{OLLAMA_BASE_URL}/v1\")\n",
    ")\n",
    "\n",
    "print(\"âœ… Imports completed successfully!\")\n",
    "print(f\"ğŸŒ Ollama endpoint: {OLLAMA_BASE_URL}\")\n",
    "print(f\"ğŸ¤– Model: {MODEL_NAME}\")\n",
    "print(\"ğŸ’¡ Using OpenAI-compatible interface with Ollama\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c19ea82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "city='London' country='United Kingdom'\n",
      "Usage(requests=1, request_tokens=163, response_tokens=378, total_tokens=541)\n"
     ]
    }
   ],
   "source": [
    "class CityLocation(BaseModel):\n",
    "    city: str\n",
    "    country: str\n",
    "\n",
    "\n",
    "ollama_model = OpenAIModel(\n",
    "    model_name=MODEL_NAME, provider=OpenAIProvider(base_url=f\"{OLLAMA_BASE_URL}/v1\")\n",
    ")\n",
    "agent = Agent(ollama_model, output_type=CityLocation)\n",
    "\n",
    "result = await agent.run('Where were the olympics held in 2012?')\n",
    "print(result.output)\n",
    "#> city='London' country='United Kingdom'\n",
    "print(result.usage())\n",
    "#> Usage(requests=1, request_tokens=57, response_tokens=8, total_tokens=65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bff9a7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available models in Ollama:\n",
      "  - deepseek-r1-qwen3-8b:latest\n",
      "  - llama3.2:1b\n"
     ]
    }
   ],
   "source": [
    "# Let's first check what models are available in Ollama\n",
    "import requests\n",
    "import json\n",
    "\n",
    "try:\n",
    "    response = requests.get(f\"{OLLAMA_BASE_URL}/api/tags\")\n",
    "    if response.status_code == 200:\n",
    "        models = response.json()\n",
    "        print(\"Available models in Ollama:\")\n",
    "        for model in models.get('models', []):\n",
    "            print(f\"  - {model['name']}\")\n",
    "    else:\n",
    "        print(f\"Failed to get models: {response.status_code}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error connecting to Ollama: {e}\")\n",
    "    print(\"Make sure Ollama is running on localhost:11434\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53f24905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Switching to model: qwen3:8b\n",
      "ğŸ“ This model should support function calling/tools\n"
     ]
    }
   ],
   "source": [
    "# Let's switch to a model that supports function calling\n",
    "# llama3.2:1b should support tools better than deepseek-r1\n",
    "# MODEL_NAME = \"llama3.2:1b\"\n",
    "MODEL_NAME = \"qwen3:8b\"\n",
    "print(f\"ğŸ”„ Switching to model: {MODEL_NAME}\")\n",
    "print(\"ğŸ“ This model should support function calling/tools\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "040375eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Agent with tools created successfully!\n",
      "ğŸ”§ Available tools:\n",
      "  - get_weather(location)\n",
      "  - calculate_circle_area(radius)\n",
      "  - get_current_time()\n",
      "\n",
      "ğŸ¯ The agent can now use these tools to answer questions!\n"
     ]
    }
   ],
   "source": [
    "# Example 1: Adding tool functions to a PydanticAI Agent\n",
    "from datetime import datetime\n",
    "import math\n",
    "from pydantic_ai import RunContext\n",
    "\n",
    "# Define response models\n",
    "class WeatherInfo(BaseModel):\n",
    "    location: str\n",
    "    temperature: float\n",
    "    description: str\n",
    "    timestamp: str\n",
    "\n",
    "class MathResult(BaseModel):\n",
    "    operation: str\n",
    "    result: float\n",
    "    explanation: str\n",
    "\n",
    "# Create agent with the new model\n",
    "ollama_model = OpenAIModel(\n",
    "    model_name=MODEL_NAME, \n",
    "    provider=OpenAIProvider(base_url=f\"{OLLAMA_BASE_URL}/v1\")\n",
    ")\n",
    "\n",
    "# Create agent - we'll add tools to this agent\n",
    "agent = Agent(ollama_model)\n",
    "\n",
    "# Method 1: Adding tools using @agent.tool decorator\n",
    "@agent.tool\n",
    "def get_weather(ctx: RunContext, location: str) -> str:\n",
    "    \"\"\"Get current weather for a location.\"\"\"\n",
    "    # This is a mock function - in real use, you'd call a weather API\n",
    "    mock_weather = {\n",
    "        \"London\": {\"temp\": 15, \"desc\": \"Cloudy\"},\n",
    "        \"Paris\": {\"temp\": 18, \"desc\": \"Sunny\"},\n",
    "        \"New York\": {\"temp\": 12, \"desc\": \"Rainy\"},\n",
    "        \"Tokyo\": {\"temp\": 22, \"desc\": \"Clear\"}\n",
    "    }\n",
    "    \n",
    "    weather = mock_weather.get(location, {\"temp\": 20, \"desc\": \"Unknown\"})\n",
    "    return f\"The weather in {location} is {weather['temp']}Â°C and {weather['desc']}\"\n",
    "\n",
    "@agent.tool\n",
    "def calculate_circle_area(ctx: RunContext, radius: float) -> str:\n",
    "    \"\"\"Calculate the area of a circle given its radius.\"\"\"\n",
    "    if radius <= 0:\n",
    "        return \"Radius must be positive\"\n",
    "    \n",
    "    area = math.pi * radius ** 2\n",
    "    return f\"The area of a circle with radius {radius} is {area:.2f} square units\"\n",
    "\n",
    "@agent.tool\n",
    "def get_current_time(ctx: RunContext) -> str:\n",
    "    \"\"\"Get the current date and time.\"\"\"\n",
    "    now = datetime.now()\n",
    "    return f\"Current time: {now.strftime('%Y-%m-%d %H:%M:%S')}\"\n",
    "\n",
    "print(\"âœ… Agent with tools created successfully!\")\n",
    "print(\"ğŸ”§ Available tools:\")\n",
    "print(\"  - get_weather(location)\")\n",
    "print(\"  - calculate_circle_area(radius)\")\n",
    "print(\"  - get_current_time()\")\n",
    "print(\"\\nğŸ¯ The agent can now use these tools to answer questions!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01e003c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ª Testing the agent with different queries that should trigger tools:\n",
      "\n",
      "1ï¸âƒ£ Testing weather tool:\n",
      "Response: <think>\n",
      "Okay, let me process the user's query and the tool response. The user asked, \"What's the weather like in London?\" I called the get_weather function with London as the location. The response came back as 15Â°C and Cloudy. Now I need to present this information clearly.\n",
      "\n",
      "First, I'll confirm the location to make sure there's no confusion. Then, state the temperature and the weather condition. I should keep it straightforward and friendly. Maybe add a sentence about the weather being mild or comfortable based on the temperature. Let me check if there's any additional info needed, but since the user only asked for the current weather, sticking to the provided details is best. Alright, time to put it all together in a natural sentence.\n",
      "</think>\n",
      "\n",
      "The current weather in London is 15Â°C with cloudy conditions. It looks like a mild and comfortable day!\n",
      "Usage: Usage(requests=2, request_tokens=608, response_tokens=311, total_tokens=919)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1269940/3906904202.py:7: DeprecationWarning: `result.data` is deprecated, use `result.output` instead.\n",
      "  print(f\"Response: {result1.data}\")\n"
     ]
    }
   ],
   "source": [
    "# Test the agent with tools\n",
    "print(\"ğŸ§ª Testing the agent with different queries that should trigger tools:\\n\")\n",
    "\n",
    "# Test 1: Weather query\n",
    "print(\"1ï¸âƒ£ Testing weather tool:\")\n",
    "result1 = await agent.run(\"What's the weather like in London?\")\n",
    "print(f\"Response: {result1.data}\")\n",
    "print(f\"Usage: {result1.usage()}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6210d513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2ï¸âƒ£ Testing math tool:\n",
      "Response: <think>\n",
      "Okay, let me check the user's question again. They asked for the area of a circle with radius 5. The tool response says the area is 78.54 square units. Wait, the function calculate_circle_area was called with radius 5, and the result is 78.54. That makes sense because Ï€ times 5 squared is approximately 3.1416 * 25 = 78.54. So the answer is correct. I should present this in a clear way to the user, maybe mention the formula used and the calculation steps. Let me make sure to format the response properly and confirm the answer.\n",
      "</think>\n",
      "\n",
      "The area of a circle with a radius of **5.0** is **78.54 square units**.\n",
      "\n",
      "This is calculated using the formula:  \n",
      "$$\n",
      "\\text{Area} = \\pi \\times r^2 = \\pi \\times 5^2 \\approx 3.1416 \\times 25 \\approx 78.54\n",
      "$$\n",
      "\n",
      "Let me know if you need further clarification! ğŸŒŸ\n",
      "\n",
      "3ï¸âƒ£ Testing time tool:\n",
      "Response: <think>\n",
      "</think>\n",
      "\n",
      "The current time is 2025-06-17 at 14:32:22.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test 2: Math calculation\n",
    "print(\"2ï¸âƒ£ Testing math tool:\")\n",
    "result2 = await agent.run(\"What's the area of a circle with radius 5?\")\n",
    "print(f\"Response: {result2.output}\")\n",
    "print()\n",
    "\n",
    "# Test 3: Current time\n",
    "print(\"3ï¸âƒ£ Testing time tool:\")\n",
    "result3 = await agent.run(\"What time is it now?\")\n",
    "print(f\"Response: {result3.output}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f3ef9a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ğŸ“š TOOL FUNCTIONS GUIDE FOR PYDANTIC AI\n",
      "============================================================\n",
      "\n",
      "âœ… Method 1: @agent.tool decorator\n",
      "   âœ“ Directly decorate functions\n",
      "   âœ“ Functions must take RunContext as first parameter\n",
      "   âœ“ Best for simple tools\n",
      "\n",
      "âœ… Method 2: Standalone Tool objects\n",
      "   âœ“ Create Tool objects explicitly\n",
      "   âœ“ More control over tool configuration\n",
      "   âœ“ Can be reused across multiple agents\n",
      "\n",
      "âœ… Method 3: Tools with complex return types\n",
      "   âœ“ Return dictionaries, lists, or custom objects\n",
      "   âœ“ Agent will serialize appropriately\n",
      "\n",
      "âœ… Method 4: Tools with error handling\n",
      "   âœ“ Handle errors gracefully\n",
      "   âœ“ Return meaningful error messages\n",
      "   âœ“ Prevent agent crashes\n",
      "\n",
      "ğŸ‰ All tool methods demonstrated!\n",
      "ğŸ’¡ Key Points:\n",
      "   â€¢ Always include RunContext as first parameter\n",
      "   â€¢ Use descriptive docstrings - the agent uses them\n",
      "   â€¢ Handle errors gracefully in your tools\n",
      "   â€¢ Tools can return strings, dicts, or complex objects\n",
      "   â€¢ Test your tools individually before using with agent\n"
     ]
    }
   ],
   "source": [
    "# ğŸ¯ COMPREHENSIVE GUIDE: Different ways to add tool functions in PydanticAI\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ğŸ“š TOOL FUNCTIONS GUIDE FOR PYDANTIC AI\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Method 1: Using @agent.tool decorator (already shown above)\n",
    "print(\"\\nâœ… Method 1: @agent.tool decorator\")\n",
    "print(\"   âœ“ Directly decorate functions\")\n",
    "print(\"   âœ“ Functions must take RunContext as first parameter\")\n",
    "print(\"   âœ“ Best for simple tools\")\n",
    "\n",
    "# Method 2: Creating standalone tools and adding them to agent\n",
    "from pydantic_ai.tools import Tool\n",
    "\n",
    "def database_query(ctx: RunContext, table: str, condition: str) -> str:\n",
    "    \"\"\"Mock database query function.\"\"\"\n",
    "    # This would normally connect to a real database\n",
    "    mock_results = {\n",
    "        \"users\": [\"Alice\", \"Bob\", \"Charlie\"],\n",
    "        \"products\": [\"Laptop\", \"Phone\", \"Tablet\"],\n",
    "        \"orders\": [\"Order #1\", \"Order #2\", \"Order #3\"]\n",
    "    }\n",
    "    results = mock_results.get(table, [\"No data found\"])\n",
    "    return f\"Query results from {table} where {condition}: {', '.join(results)}\"\n",
    "\n",
    "# Create a standalone tool\n",
    "db_tool = Tool(database_query)\n",
    "\n",
    "# Create new agent and add the tool\n",
    "agent2 = Agent(ollama_model)\n",
    "agent2._register_tool(db_tool)\n",
    "\n",
    "print(\"\\nâœ… Method 2: Standalone Tool objects\")\n",
    "print(\"   âœ“ Create Tool objects explicitly\")\n",
    "print(\"   âœ“ More control over tool configuration\")\n",
    "print(\"   âœ“ Can be reused across multiple agents\")\n",
    "\n",
    "# Method 3: Tools with complex return types\n",
    "@agent2.tool\n",
    "def search_files(ctx: RunContext, pattern: str, file_type: str = \"txt\") -> dict:\n",
    "    \"\"\"Search for files matching a pattern.\"\"\"\n",
    "    mock_files = {\n",
    "        \"txt\": [\"document1.txt\", \"notes.txt\", \"readme.txt\"],\n",
    "        \"py\": [\"main.py\", \"utils.py\", \"test.py\"],\n",
    "        \"md\": [\"README.md\", \"CHANGELOG.md\"]\n",
    "    }\n",
    "    \n",
    "    files = mock_files.get(file_type, [])\n",
    "    matching = [f for f in files if pattern.lower() in f.lower()]\n",
    "    \n",
    "    return {\n",
    "        \"pattern\": pattern,\n",
    "        \"file_type\": file_type,\n",
    "        \"matches\": matching,\n",
    "        \"total_found\": len(matching)\n",
    "    }\n",
    "\n",
    "print(\"\\nâœ… Method 3: Tools with complex return types\")\n",
    "print(\"   âœ“ Return dictionaries, lists, or custom objects\")\n",
    "print(\"   âœ“ Agent will serialize appropriately\")\n",
    "\n",
    "# Method 4: Tools with error handling\n",
    "@agent2.tool\n",
    "def safe_division(ctx: RunContext, dividend: float, divisor: float) -> str:\n",
    "    \"\"\"Safely divide two numbers with error handling.\"\"\"\n",
    "    try:\n",
    "        if divisor == 0:\n",
    "            return \"Error: Cannot divide by zero\"\n",
    "        result = dividend / divisor\n",
    "        return f\"{dividend} Ã· {divisor} = {result:.4f}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error in calculation: {str(e)}\"\n",
    "\n",
    "print(\"\\nâœ… Method 4: Tools with error handling\")\n",
    "print(\"   âœ“ Handle errors gracefully\")\n",
    "print(\"   âœ“ Return meaningful error messages\")\n",
    "print(\"   âœ“ Prevent agent crashes\")\n",
    "\n",
    "print(\"\\nğŸ‰ All tool methods demonstrated!\")\n",
    "print(\"ğŸ’¡ Key Points:\")\n",
    "print(\"   â€¢ Always include RunContext as first parameter\")\n",
    "print(\"   â€¢ Use descriptive docstrings - the agent uses them\")\n",
    "print(\"   â€¢ Handle errors gracefully in your tools\")\n",
    "print(\"   â€¢ Tools can return strings, dicts, or complex objects\")\n",
    "print(\"   â€¢ Test your tools individually before using with agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b9ee8b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ª Testing additional tools:\n",
      "\n",
      "ğŸ“Š Testing database query tool:\n",
      "Response: <think>\n",
      "Okay, let me see. The user asked to search for users in the database where active is true. I called the database_query function with table 'users' and condition 'active = true'. The response came back with the results: Alice, Bob, Charlie. Now I need to present these results to the user in a clear way.\n",
      "\n",
      "First, I should confirm that the query was executed successfully. Then list out the active users. Maybe use a friendly message to inform them of the results. Let me check if there are any other steps needed, but since the user just wanted the search, providing the list should be sufficient. I'll format the response to be easy to read.\n",
      "</think>\n",
      "\n",
      "Here are the active users found in the database:\n",
      "\n",
      "- Alice\n",
      "- Bob\n",
      "- Charlie\n",
      "\n",
      "Let me know if you need any additional information!\n",
      "\n",
      "ğŸ” Testing file search tool:\n",
      "Response: <think>\n",
      "Okay, the user asked to find all Python files containing 'main'. I used the search_files function with pattern 'main' and file_type 'py'. The response shows one match: 'main.py'. So, I should inform the user that there's one file found, which is 'main.py'. I'll present it clearly and ask if they need more details.\n",
      "</think>\n",
      "\n",
      "One Python file was found containing 'main':\n",
      "\n",
      "- `main.py`\n",
      "\n",
      "Let me know if you'd like to see the contents of this file or need further assistance!\n",
      "\n",
      "â— Testing safe division tool:\n",
      "Response: <think>\n",
      "</think>\n",
      "\n",
      "The result of dividing 100 by 7 is approximately 14.2857.\n",
      "\n",
      "âœ¨ All tools working correctly!\n"
     ]
    }
   ],
   "source": [
    "# Test the new tools\n",
    "print(\"ğŸ§ª Testing additional tools:\")\n",
    "\n",
    "# Test database tool\n",
    "print(\"\\nğŸ“Š Testing database query tool:\")\n",
    "result_db = await agent2.run(\"Search for users in the database where active = true\")\n",
    "print(f\"Response: {result_db.output}\")\n",
    "\n",
    "# Test file search tool\n",
    "print(\"\\nğŸ” Testing file search tool:\")\n",
    "result_files = await agent2.run(\"Find all Python files containing 'main'\")\n",
    "print(f\"Response: {result_files.output}\")\n",
    "\n",
    "# Test division tool\n",
    "print(\"\\nâ— Testing safe division tool:\")\n",
    "result_div = await agent2.run(\"What is 100 divided by 7?\")\n",
    "print(f\"Response: {result_div.output}\")\n",
    "\n",
    "print(\"\\nâœ¨ All tools working correctly!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pydantic_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
